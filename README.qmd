---
title: "Activity 12: Statistical reasoning 4: prediction and evaluation"
subtitle: Feb. 18th, 2026, Calvin Munson
format: gfm
execute:
  warning: false
editor: source
---

Welcome! This is the fourth statistical reasoning activity. The goals of this activity are to understand how to evaluate models and use models to make predictions. Specifically, you will:

1.    Run and interpret multiple models on the same dataset and evaluate them to see which is best supported using WAIC and PSIS.
2.    Use model output to predict how the system will behave with new data.

By making models, we are trying to approximate the processes that affect things in a system. It's important to know how well our models are actually aligning with reality though...

![XKCD-weather_balloons](photos/XKCD-weather_balloons.png)

------------------------------------------------------------------------

You will submit one output for this activity:

1.  A **PDF** of a rendered Quarto document with all of your R code. Please create a new Quarto document (e.g. don't use this `README.qmd`) and include all of the code that appears in this document, your own code, and **answers to all of the questions** in the "Q#" sections. Submit this PDF through Gradescope.

A reminder: **Please label the code** in your final submission in two ways: 

1. denote your answers to each question using headers that correspond to the question you're answering, and 
2. thoroughly "comment" your code: remember, this means annotating your code directly by typing descriptions of what each line does after a `#`. This will help future you!

------------------------------------------------------------------------

Let's start by reading in the relevant packages

```{r}
library(brms) # for statistics
library(tidyverse) # for data wrangling
library(lterdatasampler)
```


We are going to work with the fiddler crab and latitude data again:

```{r}
pie_crab <- lterdatasampler::pie_crab
```


# 1. Model comparison

It is common in the field of ecology to have multiple candidate models of how a system works. How do we know which is "best"? In this activity we will learn two metrics that can help: the Watanabe–Akaike information criterion (**WAIC**) and Pareto Smoothed Importance Sampling (**PSIS**). 

Both metrics tell us how well the model will predict data it wasn't trained on, which is important for thinking about how well the model might predict new data (as in the next section!).

---------

In this section, we will run and interpret two multiple regressions to try and understand what influences crab body width in mm (`size`). Let's remind ourselves of the columns in the crab data: 

```{r}
colnames(pie_crab)
```

We have multiple variables that may be relevant to crab body size here. Mean air and water temperature data, plus the standard deviations of each (representing variability and perhaps seasonality in temperature). 

---------

## 1.1 Create hypotheses for how each variable may affect crab size

Create four separate hypotheses describing how each predictor would be associated with larger or smaller crabs. Why? Please write 2-3 sentences for each predictor.

--------

### Q1.1a How might *mean* **water** temperature affect crab size?


--------

### Q1.1b How might *mean* **air** temperature affect crab size?


--------

### Q1.1c How might the *sd* of **water** temperature affect crab size?


--------

### Q1.1d How might the *sd* of **air** temperature affect crab size?

--------------

## 1.2 Run and interpret two different multiple regressions with latitude and **mean** temperatures

Let's run two regressions and compare their results. We will start by looking at how body size varies with latitude plus each of the mean temperature values. Since these are intertidal estuarine sites, either air or water temperatures (or both) may be important.

*   size ~ latitude + water_temp
*   size ~ latitude + air_temp

---------

### size ~ latitude + mean water temp

```{r}
# latitude and water model
m.crab.lat.water <- 
  brm(data = pie_crab, # Give the model the pie_crab data
      # Choose a gaussian (normal) distribution
      family = gaussian,
      # Specify the model here. 
      size ~ latitude + water_temp,
      # Here's where you specify parameters for executing the Markov chains
      # We're using similar to the defaults, except we set cores to 4 so the analysis runs faster than the default of 1
      iter = 2000, warmup = 1000, chains = 4, cores = 4,
      # Setting the "seed" determines which random numbers will get sampled.
      # In this case, it makes the randomness of the Markov chain runs reproducible 
      # (so that both of us get the exact same results when running the model)
      seed = 4,
      # Save the fitted model object as output - helpful for reloading in the output later
      file = "temporary/m.crab.lat.water")
```


```{r}
summary(m.crab.lat.water)
```



### size ~ latitude + mean air temp

```{r}
# latitude and air model
m.crab.lat.air <- 
  brm(data = pie_crab, # Give the model the pie_crab data
      # Choose a gaussian (normal) distribution
      family = gaussian,
      # Specify the model here. 
      size ~ latitude + air_temp,
      # Here's where you specify parameters for executing the Markov chains
      # We're using similar to the defaults, except we set cores to 4 so the analysis runs faster than the default of 1
      iter = 2000, warmup = 1000, chains = 4, cores = 4,
      # Setting the "seed" determines which random numbers will get sampled.
      # In this case, it makes the randomness of the Markov chain runs reproducible 
      # (so that both of us get the exact same results when running the model)
      seed = 4,
      # Save the fitted model object as output - helpful for reloading in the output later
      file = "temporary/m.crab.lat.air")
```


```{r}
summary(m.crab.lat.air)
```

### Q1.3  


### size ~ latitude + mean water + mean air temp

```{r}
# latitude and air model
m.crab.lat.air.water <- 
  brm(data = pie_crab, # Give the model the pie_crab data
      # Choose a gaussian (normal) distribution
      family = gaussian,
      # Specify the model here. 
      size ~ latitude + air_temp + water_temp,
      # Here's where you specify parameters for executing the Markov chains
      # We're using similar to the defaults, except we set cores to 4 so the analysis runs faster than the default of 1
      iter = 2000, warmup = 1000, chains = 4, cores = 4,
      # Setting the "seed" determines which random numbers will get sampled.
      # In this case, it makes the randomness of the Markov chain runs reproducible 
      # (so that both of us get the exact same results when running the model)
      seed = 4,
      # Save the fitted model object as output - helpful for reloading in the output later
      file = "temporary/m.crab.lat.air.water")
```


```{r}
summary(m.crab.lat.air.water)
```
## 1.3 WAIC and PSIS functions

Now we are going to compare models using the Pareto Smoothed Importance Sampling (**PSIS**) and Watanabe–Akaike information criterion (**WAIC**). Remember, both of these metrics will tell us about a model's out of sample predictive skill. Lower values = better!

First, let's look at the PSIS output

```{r}
loo(m.crab.lat.water)
```


```{r}
loo(m.crab.lat.air)
```


```{r}
loo(m.crab.lat.air.water)
```


```{r}
waic(m.crab.lat.water)
```


```{r}
waic(m.crab.lat.air)
```


```{r}
waic(m.crab.lat.air.water)
```





--------

# 2. Predictions

![StrangePlanet_NathanPyle_weatherForecasting](photos/StrangePlanet_weatherForecasting.jpeg)

--------

### Render to PDF

When you have finished, remember to pull, stage, commit, and push with GitHub:

-   Pull to check for updates to the remote branch
-   Stage your edits (after saving your document!) by checking the documents you'd like to push
-   Commit your changes with a commit message
-   Push your changes to the remote branch

Then submit the well-labeled PDF on Gradescope. Thanks!
